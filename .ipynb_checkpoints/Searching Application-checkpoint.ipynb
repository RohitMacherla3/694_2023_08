{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62115f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pymongo\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import mysql.connector as cnx\n",
    "import pickle\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9b4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to mysql server\n",
    "mydb = cnx.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"root@123\",\n",
    "  database=\"mydatabase\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7cff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to mongodb\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\") \n",
    "db = client[\"Tweets_DB\"]\n",
    "tweets_collec = db[\"Tweets_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad09098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    def __init__(self, max_size=15000, evict_strategy='least_accessed', checkpoint_interval=30, ttl=None):\n",
    "        self.max_size = max_size\n",
    "        self.evict_strategy = evict_strategy\n",
    "        self.checkpoint_interval = checkpoint_interval\n",
    "        self.ttl = ttl\n",
    "        self.cache = {}\n",
    "        self.access_count = {}\n",
    "        self.last_checkpoint = time.time()\n",
    "    \n",
    "        if os.path.exists('cache.checkpoint'):\n",
    "            self.load_from_checkpoint('cache.checkpoint')\n",
    "\n",
    "    def load_from_checkpoint(self, checkpoint_file):\n",
    "        with open(checkpoint_file, 'rb') as f:\n",
    "            self.cache, self.access_count = pickle.load(f)\n",
    "\n",
    "    def save_to_checkpoint(self, checkpoint_file):\n",
    "        with open(checkpoint_file, 'wb') as f:\n",
    "            pickle.dump((self.cache, self.access_count), f)\n",
    "            \n",
    "    def get(self, key):\n",
    "        \n",
    "        if key[0].isdigit() or key.startswith('#'):\n",
    "            if key not in self.cache:\n",
    "                return None\n",
    "            similar_keys = [key]\n",
    "            \n",
    "        else:\n",
    "            similar_keys = []\n",
    "            for k in self.cache:\n",
    "                if key in k:\n",
    "                    similar_keys.append(k)\n",
    "\n",
    "            if len(similar_keys) == 0:\n",
    "                return None\n",
    "        \n",
    "        if self.ttl is not None and (time.time() - self.cache[key]['timestamp']) > self.ttl:\n",
    "            del self.cache[key]\n",
    "            del self.access_count[key]\n",
    "            return None\n",
    "        \n",
    "        for i in similar_keys:\n",
    "            self.access_count[i] += 1\n",
    "            \n",
    "            if self.evict_strategy == 'least_accessed':\n",
    "                least_accessed_key = min(self.access_count, key=self.access_count.get)\n",
    "                if len(self.cache) > self.max_size and key != least_accessed_key:\n",
    "                    del self.cache[least_accessed_key]\n",
    "                    del self.access_count[least_accessed_key]\n",
    "                \n",
    "        return [self.cache[k]['value'] for k in similar_keys]\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if not key.startswith('#'):\n",
    "            key = key.lower()\n",
    "        self.cache[key] = {'value': value, 'timestamp': time.time()}\n",
    "        self.access_count[key] = 0\n",
    "        if len(self.cache) > self.max_size:\n",
    "            if self.evict_strategy == 'least_accessed':\n",
    "                least_accessed_key = min(self.access_count, key=self.access_count.get)\n",
    "                del self.cache[least_accessed_key]\n",
    "                del self.access_count[least_accessed_key]\n",
    "            elif self.evict_strategy == 'oldest':\n",
    "                oldest_key = min(self.cache, key=lambda k: self.cache[k]['timestamp'])\n",
    "                del self.cache[oldest_key]\n",
    "                del self.access_count[oldest_key]\n",
    "                \n",
    "        if (time.time() - self.last_checkpoint) > self.checkpoint_interval:\n",
    "            self.save_to_checkpoint('cache.checkpoint')\n",
    "            self.last_checkpoint = time.time()\n",
    "            \n",
    "    def print_cache(self):\n",
    "        print('Cache:')\n",
    "        for key, value in self.cache.items():\n",
    "            print(f\"{key}\")\n",
    "        used_space = len(self.cache)\n",
    "        remaining_space = self.max_size - used_space\n",
    "        print(f\"Cache size: {used_space}\")\n",
    "        print(f\"Remaining space: {remaining_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb306a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05dd424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tweet counte per each user\n",
    "def count_tweets_per_user():\n",
    "    tweet_counts = {}\n",
    "    cursor = tweets_collec.aggregate([\n",
    "        {\"$group\": {\"_id\": \"$User_Id\", \"count\": {\"$sum\": 1}}}\n",
    "    ])\n",
    "    for user in cursor:\n",
    "        tweet_counts[user['_id']] = user['count']\n",
    "    return tweet_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25d8282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the results to a csv file to load it into mysql database\n",
    "def write_tweets_to_csv(filename, tweets_dict):\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['User_ID', 'Tweets_Count'])\n",
    "        for user_id, count in tweets_dict.items():\n",
    "            writer.writerow([str(user_id), count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08478a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dict = count_tweets_per_user()\n",
    "write_tweets_to_csv('tweets_counts.csv', tweets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93caba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the search term starts with '@'\n",
    "def UserSearch(search_term):\n",
    "    \n",
    "    if search_term.startswith('@'):\n",
    "    # remove the '@' symbol from the search term\n",
    "        search_term = search_term[1:]\n",
    "        \n",
    "        if cache.get(search_term):\n",
    "            print(\"getting\")\n",
    "            results = cache.get(search_term)\n",
    "            \n",
    "        else:\n",
    "            print(\"putting\")\n",
    "            # execute the query to search for user details based on username\n",
    "            query = \"\"\"\n",
    "                SELECT * FROM users \n",
    "                WHERE name LIKE %s \n",
    "                ORDER BY followers_count DESC, tweets_count DESC, verified DESC\n",
    "                LIMIT 5\n",
    "                \"\"\"\n",
    "            mycursor.execute(query, ('%' + search_term + '%',))\n",
    "            results = mycursor.fetchall()\n",
    "            for i in range(0,len(results)):\n",
    "                cache.put(results[i][1], results[i])\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d26bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_tweets(user_id):\n",
    "    \n",
    "    if cache.get(user_id):\n",
    "        print(\"getting tweet\")\n",
    "        tweet_details = cache.get(user_id)\n",
    "    \n",
    "    else:\n",
    "        print(\"putting tweet\")\n",
    "        \n",
    "        user_tweets = list(tweets_collec.find({'User_Id': user_id}).sort([('created_at', -1)]).limit(3))\n",
    "        tweet_details = []\n",
    "        \n",
    "        for tweet in user_tweets:\n",
    "            tweet_details.append({\n",
    "                'created_at': tweet['created_at'],\n",
    "                'text': tweet['Text'],\n",
    "                'hashtags': tweet['Hashtag'],\n",
    "                'retweet_count': tweet['Retweet_Count'],\n",
    "                'likes_count': tweet['Likes_Count']\n",
    "            })\n",
    "        \n",
    "        cache.put(user_id, tweet_details)\n",
    "    return tweet_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00e085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserPrint(results):\n",
    "    for result in results:\n",
    "        user_id = result[0]\n",
    "        tweets_cache[user_id] = get_user_tweets(user_id)\n",
    "        if result[3]==1:\n",
    "            verified_status=\"✅\"\n",
    "        else:\n",
    "            verified_status=\"❌\"\n",
    "            /\n",
    "        line1 = \"Name: {} | Verified: {}\".format(result[1], verified_status)\n",
    "        # format the remaining fields in another line\n",
    "        line2 = \"Followers: {} | Tweets: {}\".format(result[4], result[8])\n",
    "        line3 = \"Description : {}\".format(result[9])\n",
    "        line4=\"Location : {} | Creation Date:{}\".format(result[7],result[6])\n",
    "        \n",
    "        # print both lines\n",
    "        print(line1)\n",
    "        print(line2)\n",
    "        print(line3)\n",
    "        print(line4)\n",
    "        print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0abbb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the search term: e\n",
      "Time for getting user info:  6.216698966454715e-05\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m start_mongo \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     11\u001b[0m tweets_cache \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 12\u001b[0m UserPrint(\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m end_mongo \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     14\u001b[0m mongo_time \u001b[38;5;241m=\u001b[39m end_mongo \u001b[38;5;241m-\u001b[39m start_mongo\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "search_term = input(\"Enter the search term: \")\n",
    "\n",
    "start_sql = time.perf_counter()\n",
    "results=UserSearch(search_term)\n",
    "end_sql = time.perf_counter()\n",
    "\n",
    "sql_time = end_sql - start_sql\n",
    "print(\"Time for getting user info: \", sql_time)\n",
    "\n",
    "start_mongo = time.perf_counter()\n",
    "tweets_cache = {}\n",
    "UserPrint(results[:3])\n",
    "end_mongo = time.perf_counter()\n",
    "mongo_time = end_mongo - start_mongo\n",
    "print(\"Time for getting tweets info: \", mongo_time)\n",
    "\n",
    "    # check if there are more results\n",
    "if len(results) > 3:\n",
    "        # prompt the user to load more results\n",
    "    load_more = input(\"Load more results? (yes/no) \")\n",
    "    if load_more.lower().startswith('y'):\n",
    "        UserPrint(results[3:5])\n",
    "user_choice = int(input(\"Enter the number of the user whose tweets you want to see: \"))\n",
    "\n",
    "# Get the user_id of the selected user\n",
    "user_id = results[user_choice-1][0]\n",
    "\n",
    "# Display the tweets of the selected user\n",
    "\n",
    "if user_id in tweets_cache:\n",
    "    print(f\"Tweets of {results[user_choice-1][1]}:\")\n",
    "    for tweet in tweets_cache[user_id]:\n",
    "        print(tweet)\n",
    "else:\n",
    "    print(\"No tweets found for the selected user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search by hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_hashtags(search_string, limit=5):\n",
    "    \n",
    "    if search_string.startswith('#'):\n",
    "        search_string = search_string[1:]\n",
    "        \n",
    "        hashtags = tweets_collec.aggregate([\n",
    "        { \"$match\": { \"Hashtag\": { \"$regex\": search_string, \"$options\": \"i\" } } },\n",
    "        { \"$unwind\": \"$Hashtag\" },\n",
    "        { \"$group\": { \"_id\": \"$Hashtag\", \"count\": { \"$sum\": 1 } } },\n",
    "        { \"$sort\": { \"count\": -1 } },\n",
    "        { \"$limit\": limit }\n",
    "        ])\n",
    "        \n",
    "        hashtag_dict = {}\n",
    "        for hashtag in hashtags:\n",
    "            hashtag_dict[hashtag['_id']] = hashtag['count']\n",
    "            \n",
    "        return hashtag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81771c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_of_hashtag(hashtag):\n",
    "    \n",
    "    if cache.get('#' + hashtag):\n",
    "        tweets = cache.get(hashtag)[0]\n",
    "    else:\n",
    "        tweets = list(tweets_collec.find({'Hashtag': hashtag}).sort('created_at', -1).limit(3))\n",
    "        cache.put('#' + hashtag, tweets)\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hashtag_print(hashtags):\n",
    "    print()\n",
    "    print(\"Top 5 hashtags matching the search string: \")\n",
    "    print()\n",
    "    for k,v in hashtags.items():\n",
    "        print(\"------------------------------------------\")\n",
    "        print(\"Hashtag: {} | Tweets Count: {}\\n\".format(k, v))\n",
    "    \n",
    "    for hashtag in hashtags.keys():\n",
    "        temp_hashtag[hashtag] = tweets_of_hashtag(hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 1 display\n",
    "search_hashtag = input(\"Enter the hashtag: \")\n",
    "hashtags = get_top_hashtags(search_hashtag)\n",
    "\n",
    "temp_hashtag = {}\n",
    "\n",
    "start_hashtag = time.perf_counter()\n",
    "Hashtag_print(hashtags)\n",
    "end_hashtag = time.perf_counter()\n",
    "hashtag_time = end_hashtag - start_hashtag\n",
    "print(\"Time for getting tweets info: \", hashtag_time)\n",
    "\n",
    "print()\n",
    "hashtag_choice = input(\"Enter the hashtag whose tweets you want to see: \")\n",
    "\n",
    "if hashtag_choice in temp_hashtag:\n",
    "    print()\n",
    "    print(f\"Tweets of {hashtag_choice}:\")\n",
    "    for tweet in temp_hashtag[hashtag_choice]:\n",
    "        line_1 = \"User: {} | Retweets: {} | Likes: {} | Created at: {}\".format(tweet['User_Name'], tweet['Retweet_Count'], tweet['Likes_Count'], tweet['created_at'])\n",
    "        line_2 = \"Text: {}\".format(tweet['Text'])\n",
    "        \n",
    "        print(\"----------------------------------------------------------------------------------\")\n",
    "        print()\n",
    "        print(line_1)\n",
    "        print(line_2)\n",
    "        print(\"Hashtags: {}\".format(tweet['Hashtag']))\n",
    "else:\n",
    "    print(\"No tweets found for the selected hashtag.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9afb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c6a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 users with most followers, tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e98a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserPrint1(results):\n",
    "    for result in results:\n",
    "        if result[3]==1:\n",
    "            verified_status=\"✅\"\n",
    "        else:\n",
    "            verified_status=\"❌\"\n",
    "            \n",
    "        line1 = \"ID: {} | Name: {} | Verified: {}\".format(result[0], result[1], verified_status)\n",
    "        # format the remaining fields in another line\n",
    "        line2 = \"Followers: {} | Tweets: {}\".format(result[4], result[8])\n",
    "        line3 = \"Description : {}\".format(result[9])\n",
    "        line4=\"Location : {} | Creation Date:{}\".format(result[7],result[6])\n",
    "        \n",
    "        # print both lines\n",
    "        print(line1)\n",
    "        print(line2)\n",
    "        print(line3)\n",
    "        print(line4)\n",
    "        print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6733d0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 813286 | Name: Barack Obama | Verified: ✅\n",
      "Followers: 116518121 | Tweets: 1\n",
      "Description : Dad, husband, President, citizen.\n",
      "Location : Washington, DC | Creation Date:2007-03-05 22:08:25\n",
      "--------------------------------------------\n",
      "ID: 25073877 | Name: Donald J. Trump | Verified: ✅\n",
      "Followers: 78467254 | Tweets: 0\n",
      "Description : 45th President of the United States of America🇺🇸\n",
      "Location : Washington, DC | Creation Date:2009-03-18 13:46:38\n",
      "--------------------------------------------\n",
      "ID: 428333 | Name: CNN Breaking News | Verified: ✅\n",
      "Followers: 57529057 | Tweets: 0\n",
      "Description : Breaking news from CNN Digital. Now 56M strong. Check @cnn for all things CNN, breaking and more. Download the app for custom alerts: http://cnn.com/apps\n",
      "Location : Everywhere | Creation Date:2007-01-02 01:48:14\n",
      "--------------------------------------------\n",
      "ID: 18839785 | Name: Narendra Modi | Verified: ✅\n",
      "Followers: 55781248 | Tweets: 6\n",
      "Description : Prime Minister of India\n",
      "Location : India | Creation Date:2009-01-10 17:18:56\n",
      "--------------------------------------------\n",
      "ID: 44409004 | Name: Shakira | Verified: ✅\n",
      "Followers: 52250613 | Tweets: 0\n",
      "Description : 🎙ME GUSTA Shakira & Anuel AA Nuevo Sencillo / New Single\n",
      "Location : Barranquilla | Creation Date:2009-06-03 17:38:07\n",
      "--------------------------------------------\n",
      "ID: 759251 | Name: CNN | Verified: ✅\n",
      "Followers: 47567385 | Tweets: 0\n",
      "Description : It’s our job to #GoThere & tell the most difficult stories. Join us! For more breaking news updates follow @CNNBRK  & Download our app http://cnn.com/apps\n",
      "Location : None | Creation Date:2007-02-09 00:35:02\n",
      "--------------------------------------------\n",
      "ID: 807095 | Name: The New York Times | Verified: ✅\n",
      "Followers: 46359985 | Tweets: 1\n",
      "Description : News tips? Share them here: http://nyti.ms/2FVHq9v\n",
      "Location : New York City | Creation Date:2007-03-02 20:41:42\n",
      "--------------------------------------------\n",
      "ID: 5402612 | Name: BBC Breaking News | Verified: ✅\n",
      "Followers: 43014510 | Tweets: 0\n",
      "Description : Breaking news alerts and updates from the BBC. For news, features, analysis follow @BBCWorld (international) or @BBCNews (UK). Latest sport news @BBCSport.\n",
      "Location : London, UK | Creation Date:2007-04-22 14:42:37\n",
      "--------------------------------------------\n",
      "ID: 145125358 | Name: Amitabh Bachchan | Verified: ✅\n",
      "Followers: 41596464 | Tweets: 1\n",
      "Description : \"तुमने हमें पूज पूज कर पत्थर कर डाला ; वे जो हमपर जुमले कसते हैं हमें ज़िंदा तो समझते हैं \"~  हरिवंश राय  बच्चन\n",
      "Location : Mumbai, India | Creation Date:2010-05-18 05:16:47\n",
      "--------------------------------------------\n",
      "ID: 132385468 | Name: Salman Khan | Verified: ✅\n",
      "Followers: 40094611 | Tweets: 0\n",
      "Description : Film actor, artist, painter, humanitarian\n",
      "Location : MUMBAI | Creation Date:2010-04-13 02:56:21\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select * from mydatabase.users \n",
    "order by followers_count DESC,tweets_count DESC \n",
    "limit 10\"\"\"\n",
    "\n",
    "mycursor.execute(query)\n",
    "results = mycursor.fetchall()\n",
    "UserPrint1(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1484415a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
